\clearpage

\section{Introduction}

[TODO: Intention, hypotheses and results of the study]

Ethical, legal and social considerations are also part of my thesis.


Discussion centers on potential practical implications of the present results, as well as on prospects for future research.

\clearpage

\section{Background}

	\subsection{Motivation}
	
	\input{motivation.tex}
	
		
	\subsection{Research basis} \label{sec:research}
	
	\toDo{about 10 pages of research}
	
	Information architecture and display types play an important role in learning comprehension, attention and learning success. \cite{McCrudden2017} describe the effects of different types of visual display on cognitive processing. They highlight the important aspects of visual guidelines, the basics of human understanding and  memory, as well a way to quantify those under processing efficiency. One of their conclusions is that "displays should be designed to support the selection of important information" \cite[p.633]{McCrudden2017}
	
	There is, however, a case to be made with respect to the same visual display that can be put forth in front of participants under differentiating emotional states. There is strong evidence that emotions play a role in information processing and, as a consequence, can have an effect on the resulting performance. Section \ref{sec:emotion-cognition} discusses closer existing research supporting a connection between emotion and cognition
	
	A recent study \cite{Haaranen2015} suggests that wrong choice of emotional design patterns can yield contra-productive results. It reports lover concentrations levels in the experiment group compared to control group using abstract graphics when learning object-oriented programming (OOP). Due to their choice of presentation and the topic or learning, the material has not been perceived as serious and a such became distracting.
		
		\subsubsection{Emotion theory}
		
		\toDo{[TODO]: summarize Valence-Arousal model and explain 4 groups}
		
		\subsubsection{Emotion and cognition} \label{sec:emotion-cognition}
		
		A 2004 cognitive neuroscience study \cite{Dolcos2004} scanned participants brain activity, while rating emotional pictures. The study suggests several relevant conclusions. First, that different parts of the brain show stronger activity when exposed to positive compared to negative stimuli. Second, that high arousal stimuli lead to greater successful encoding activity, or in other words - rate of recall, than neutral stimuli. 
		
		In other words, brain response is different for arousing stimuli of positive valence compared to negative valence. Furthermore memory is mediated, in part by both - valence and arousal levels. It provides basis to the assumption that variation on both dimensions is necessary to adequately reflect effects within e-learning context. Study design in \ref{sec:study-design} depends heavily on this assumption.
		
		\subsubsection{Emotion and visual interface}
		
		\cite{Desmet2007} demonstrates in their research that physical objects can cause significant emotional response and that modifying design attributes can successfully contribute to creating of desired response.
		Both physical objects and digital visuals are, in essence, interfaces. Both can cause an emotional response \citationneeded Digital interfaces are extremely flexible to experimentation and modification at low cost.
	
	\subsection{Hypotheses}
	
		\paragraph{Hypothesis 1.} Two different interfaces do not result in a significant difference in emotional response
		\paragraph{Hypothesis 2.} Performance or participants on tasks, as measured by selected study design parameters, during the experiment is equal with interface 1, and with interface 0.

\section{Approach and Methods}

To facilitate the study I make assumptions about the medium in which e-learning is usually conducted. Based on previous research (\ref{sec:research}) I define study design parameters and a set of target variables that are measured and evaluated.

	\subsection{Medium}
	
	The study is to be conducted online under a "real-life" scenario. This means, that the experiment is to be run in a browser-capable web-application runnable on modern personal computers. Like most e-learning software the  application used in the study is browser-based and usually used in a user's home or public venue.
	
	\subsection{Study design} \label{sec:study-design}
	
	Goal of the current study is to determine emotional response difference to provided emotional design implementation (Interface 1) compared to the control group that is provided with a stricter desaturated design (Interface 0). Differences include use of color, shapes, language, font style, interaction responsiveness, animation. The similarities or - constant variables - across both interfaces include any accessibility features and general usability heuristics, such as contrast ratio level, size and placement of elements on a screen.
	
	Participants of the study are not informed about the existence of another interface as a variable but rather only made aware about being emotionally influenced by preconditioning and that their performance during the experiment is being measured. Abundance of timers throughout the test highlight the time sensitivity of the tasks to the participant.
	
	The experiment can be outlined and split into following steps:
	
	\begin{enumerate}
		
		\item[0.] \textbf{Clustering:} Each participant is assigned an interface version (1 of 2) and the preconditioning group (1 of 4) at random before first load of the application.
		
		\item \textbf{Emotional report:} A short emotional self-reporting questionnaire (SAM \ref{sec:selfeval}) is used to acquire initial valence and arousal ratings
		
		\item \textbf{Preconditioning:} Each participant is shown a set of emotional images and preconditioned to be in one of 4 states:
			\textbf{1}: Positive valence / high arousal;
			\textbf{2}: Negative valence / high arousal;
			\textbf{3}: Positive valence / low arousal;
			\textbf{4}: Negative valence / low arousal;
			
		Choice of stimuli and their presentation is described further in chapter \ref{preconditioning}
			
		\item \textbf{Emotional report:} Emotional self-reporting questionnaire (SAM \ref{sec:selfeval}) to validate, whether preconditioning has had a sufficient and expected effect on the participant.
		
		\item \textbf{Experiment 1:} Slightly modified classic memory game. The participant is presented with a grid of tiles, each tile containing an image. During 10 seconds at the beginning of the experiment all tiles are open to allow to memorize the images. After which all images are hidden. Only 2 tiles can be opened at any one time. Once both tiles of the same image are open they are marked as solved. The goal is to solve all tiles. \ref{sec:memory}
		
		\item \textbf{Experiment 2:} Remote Associates Test (RAT). A generalized creativity test developed by Mednick \cite{Mednick1962} in 1962. Each participant is presented with a number of word sets. Each set consists of 3 words that are shown to the participant and one target word that is hidden from the them. The target word is semantically connected to all 3 visible words \ref{sec:creativity}
		
		\item \textbf{Emotional report:} A second emotional self-reporting questionnaire (SAM \ref{sec:selfeval}) is used to establish, whether and which effect tasks and interface have had on the participant's emotion.
		
		\item \textbf{Demographic data:} Final step adds additional personal context data for each participant through a questionnaire to complement data analysis (discussed in \ref{sec:demographics}).
		
	\end{enumerate}
	
	\subsection{Preconditioning sequences} \label{preconditioning}
	
	\input{2-choosing-a-preconditionining-sequence.tex}
	
	\subsection{Emotional Design Features}

Under real conditions it can be expected that the e-learning interface will cause mild-to-moderate changes to a mood.
	
	\toDo{write about emotional design, rewrite citation blocks below}
	
	\input{1-developing-high-performing-interface.tex}
	
	\subsection{Experiments}

		\subsubsection{Experiment 1: Short term Memory} \label{sec:memory}
		
		Memory Experiment 
		
		[TODO:] Describe basis of the experiment
		
		[TODO:] describe activity logging for EXP1 here?
		
		\paragraph{Performance variables:} \label{sec:memory-parameters}
		
				[TODO:] measuring performance of this experiment
		
		\subsubsection{Experiment 2: Creative thought} \label{sec:creativity}
		
		A generalized creativity test developed by Mednick \cite{Mednick1962} in 1962. The test is developed in such a way that does not require prior knowledge of any particular subject. 
		
		A possible limitation is knowledge of language and cultural influence. Mednick himself states that "verbal associative habits could reasonably be assumed to be familiar to almost all individuals that have been brought up in this (USA) culture". The originally presented 30-element list of problems can have a certain dependency on the cultural linguistic habits. Additional steps are taken to exclude possible problems due to these effects. \
		
		To minimize the limitation of language knowledge participant is required at the beginning of the study to comply with conditions, which contain (among others) "advanced English knowledge" (Appendix \ref{itm:participation_requirements}), the participants are later asked to state whether they are native English speakers.
		 
		
		
		\begin{figure}[h]
			\centering
			\includegraphics[height=0.3\textheight]{graphics/Example_RAT_Set}
			\caption{Example remote associate word-set "Cottage, Swiss, Cake"}
			\label{fig:exampleratset}
		\end{figure}


		In a 2003 paper Bowden et al. \cite{Bowden} have developed 144 sets of RAT problems with an additional constraint. The solution word has to not only be related to the triad of stimulus words but additionally each of them should form a commonly used compound word or two-word phrase with the solution word.
		Bowden's word-sets are a subset of all possible remote associate problems and have been alternatively described as "compound word problems".
		
		\toDo{longer description of what Bowden proposes with some quotes}
		
		Some \textbf{20} of a set of 144 compound remote associate sets are taken from \cite{Bowden}. Some of the easier (top solving percentage rate among 30-second threshold test participants, published by Bowden) word-sets are selected for present experiment while avoiding certain colloquialisms related to a location. As a result, these 20 word-sets should be challenging although solvable to a wide array of people from different backgrounds. Table \ref{table:1} presents a list of the used RAT items in the current study. The difference in time taken to solve a problem act as indicator for performance. (\ref{sec:creativity-parameters}).
		
		\paragraph{Experiment details}
		
		The participant is informed about the rules and what is expected from them:
		
		\begin{displayquote}
			"You will see three stimulus words. Attempt to generate a fourth word that is related to each stimulus word. When combined with each of the stimulus words will build a word pair that is a common compound word or phrase. The goal is to find a solution as fast a possible
			
			After 30 seconds you will see 2 words appearing as hints on the screen, only one solution is correct.
			The first 3 are practice sets and will allow you to train. During practice we will give you a hint after 10 seconds"
		\end{displayquote}
	
		The participant is shown 3 practice tasks which allow them to get used to the interface and the dynamics of the task. As most of the participants are remote and unsupervised it is important to give an intuitive set of instructions and avoid any variation due to unclear interface or task.
		
		\begin{figure}[h]
			\centering
			\includegraphics[width=0.7\linewidth]{"graphics/creativity versions"}
			\caption{Example screen showing both versions of interface during creativity experiment}
			\label{fig:creativity-versions}
		\end{figure}
	
		After 3 practice tasks, participant clicks on "Start Experiment" before solving 20 items defined in the set. An example preview of both interface screens with the three stimulus words and an input for the answer is displayed in figure \ref{fig:creativity-versions} 
		
		Upon appearance of each word-set a timer starts tracking the time to enter a word.
		Stimulus words appear with a 200ms delay from timer start and 50ms delay between each word appearing. The appearance animation takes 300ms. All items are completely visible at 600ms mark, with the first word in the left-to-right direction completely visible and static at 500ms after timer start. 500ms can be discounted from the time it takes to solve a problem (Effectively participants have 29.5 seconds to solve a problem).
		
		\paragraph{Appearance of Hints}
		
		Each word-set has a 30 second limit to solve a problem. After time is expired a block with 2 hint words \ref{fig:hint-buttons} appear. One of which is the correct solution to the problem, another is a false solution. It is semantically clear which solution is correct, upon reading it the participant is expected to experience the "aha!" effect mentioned in \cite[p.634]{Bowden} with a reference to previous research. Choosing the wrong answer, once the time expires can be a hint that the participant is not paying attention.
		
		After hints appear, the problem is not any more counted as solved by the participant. 
		
		\textit{Hints appearance can be delayed.} Due to a person requiring typing the answer on a keyboard it is assumed the answer is known once the first letter of the word is written in the field. There is a 3000ms grace delay to type each additional character. Grace delay accounts for typing speed and is deemed sufficient for most persons. Erasing a character is considered as typing (and resets the counter) unless the first letter of the input is erased. Once the delay is passed or the first letter erased the hints appear and the problem is marked as unsolved. Time of the first letter being typed is considered an objective point of time that a participant figures out the answer to the problem. The time of first letter is always within 30 seconds of appearance of the word-set.
		
		\begin{figure}
			\centering
			\includegraphics[width=0.3\linewidth]{"graphics/Hint buttons"}
			\caption{Hints after time allowed for solving a problem is elapsed}
			\label{fig:hint-buttons}
		\end{figure}
		
		
		Once all items are solved they are directed to the next page of the interface.
				
		\paragraph{Activity logging} \textit{Experiment 2} activity is specified based upon generalized logging of activity in e-learning described in \ref{sec:activitylog}
		
		The test is connected with a generic action emitter. An action triggered in the following cases:
		
		\begin{itemize}
			\item Click on button to start practice
			\item Click on button to start live experiment
		\end{itemize}
	
			\toDo{Explain more activity logging}

		\paragraph{Performance variables} \label{sec:creativity-parameters}
		
		\begin{enumerate}
			\item Aggregated solving speed: seconds taken to solve a problem on average
			\item Non-aggregated solving speed: seconds taken to solve each problem
			\item Idea generation ratio: how many attempts (including false ones) are taken withing the time limit on average
			\item Success rate: Number of problems solved successfully
			\item Frustration/Attention: Amount of false choices after \textit{Hint Word} suggestion appears as ratio to Hint Word suggestion answers.
		\end{enumerate}
	
		[TODO:] elaborate about the measures and reasoning behind them


	\subsection{Means of emotional self-evaluation} \label{sec:selfeval}
	
	\input{means-of-self-evaluation.tex}
	
	[TODO:] Describe Valence and Arousal evaluation techniques
	
	SAM , AS, Affect Grid \cite{Russell1989}
	
	Due to effort constraints of the participants it is important to achieve a simple, yet accurate reading of their emotions. In the context of this study self-evaluation is a means to validate results, of Hypothesis 1. I chose to rely on the proven SAM (Self-Assessment Manikin) method \cite{Bradley1994} to quickly allow users to assess their emotions on a dual 9 element scale.
	
	\subsection{Demographic data and supplemental information} \label{sec:demographics}
	
	As final step of the study each participant fills out a demographics questionnaire to add context data and help with analysis. There are 4 questions:
	
	\begin{enumerate}
		\item Gender \\ \ [Male / Female]
		\item Age \\ \ [18-24 / 25-29 / 30-34 / 35 - 44 / older]
		\item Is English your native language? \\ \ [yes / no]
		\item What is your level of English knowledge? \\ \
			[Beginner  / Intermediate / Advanced / Fluent]
		\item Occupation: \\ \ [High school student / Undergraduate Student / Graduate Student / Doctorate / Professional or Working]
	\end{enumerate}

	The age groups are taken in accordance with suggestions provided by the Standard International Age Classifications \cite{UN1982} with slight modifications to exclude ages below 18. Further the study would focus on ages up to 44. Ages above 44 could potentially skew results due factors not considered by present study. Primary focus audience lies between ages of 18 and 34.
	
	Question 4 is used to validate the requirement of at least an "advanced" proficiency in English. Participant choosing anything lower could suggest either invalid data or problems with the creativity task due to language issues. In this case participant will be considered for removal. \todo{evaluate this claim}
	
	Last field allows the user to enter their email address for participation in the raffle and complies with the motivational promise at the beginning of the experiment.

	\subsection{E-learning activity logging} \label{sec:activitylog}
	%\input{activity-logging.tex}
	
	\toDo{[TODO:] Describe general approach to recording actions and recording approach for this study.}
	
	Each participant is defined as a \textit{user}. Each user is assigned a session for each new started experiment. 
	
	To assess the performance of participants continuous measurements are taken during a session of the experiment. A general approach is an event-based system where each \textbf{action} from the \textit{user} or the \textit{system} is emitted to the database. A differentiation is established between a "click" action that is initiated by the user and an "event" action that is initiated by the system environment.
	
	For correct attribution at the moment when action is emitted it contains: 
	\begin{itemize}
		\item userID, sessionID, timestamp (unique key)
		\item name of active screen
		\item type of action (\textit{event} or \textit{click})
		\item context information such as global system state and dependent values of current active screen
	\end{itemize}

	Finally, for system actions (events) \textbf{name of event} is provided. For user actions (clicks) a target of the click is provided.
	
	%A session is defined on the scope of single e-learning module and contains user metadata as well as emotional state of the learner.

	

		
		\paragraph{Technical implementation}
		
		Upon requesting the page a user-token is generated and assigned to each participant. This token is saved as a cookie for future reference and visitor matching. Only one successful experiment is allowed per participant due to 
		Each experiment further contains a session object with its attributes. 
		
		"[location]\_[action]\_[result]"
		
		\toDo{[TODO:] describe how tracking is implemented, storage and analysis for current study}
		
		Action tracking is managed by a dedicated module that communicates with the database storage API. Each event sent to the Database is complemented with a timestamp and user data. An action object with usual fields is described in listing \ref{lst:db_object}


	\begin{listing}[H]
		\begin{minted}{json}
			{
			"first": "second1"
			}
		\end{minted}
		\caption{Database Object Fields}
		\label{lst:db_object}
	\end{listing}


		
		\paragraph{xAPI adaptation} - 
		
		\toDo{[TODO Optional:] explore adaptability and possible constraints}

\section{Study implementation}

\input{study-implementation.tex}

\paragraph{Technical implementation} is guided by the requirement to run the study in a browser on a personal computer. React.js is selected as a library of choice due to it's favorable characteristics to creating an environment that supports 2 themes and global settings in a scalable way. 


React's unidirectional data flow allows clear behavior path between application data and visual representation. In particular, it becomes possible to adjust the theme of the interface and propagate in-place an alternative style and visual rules throughout the application without losing current state. Additional benefits of this approach are discussed in section \ref{sec:further-research} in the context of an emotionally aware interface.

\begin{figure}
	\centering
	\includegraphics[width=1\linewidth]{"graphics/App Architecture"}
	\caption{Component based architecture with emotion control mechanism}
	\label{fig:app-architecture}
\end{figure}

Current implementation contains a minimal proof of concept of a way to enable e-learning interfaces to be complemented with emotional data. On one side data about the nature of the task, as discussed by \cite{Haaranen2015} and acknowledged in section \ref{sec:research}. On the other side about the emotional state of the user, either through ambient and body-sensors, or by other means.

Through this architecture (as shown in figure \ref{fig:app-architecture}), it is possible to develop an interface that responds to emotional and task contexts with an appropriate interface.

\section{Results and Evaluation}

	\subsection{Collected data}
	
	[TODO:] Describe data preparation, how many people participated, demographics data, distributions.
	[TODO:] Show general statistical data
	
	\subsection{Evaluation}
	
	[TODO:] Here describe how evaluation was done
	
\section{Conclusions}

	\subsection{Hypothesis 1}
	
	[Note:] H1 should be checked in the context of the whole app
	
	\subsection{Hypothesis 2}
	
	[Note:] H2 should be checked for each task separately

\section{Further research and implications of the study} \label{sec:further-research}

\subsection{Ethical, legal and social implications}

[TODO]

\section{Notes}




